EMOTION 숙제
==============================================
# 수치예측 

## 선형 회귀
!<img src="http://i.imgur.com/lCKBBDV.png"> <br>
선형 회귀 개념 : 선형 회귀(linear regression)는 종속 변수 y와 한 개 이상의 독립 변수 (또는 설명 변수) X와의 선형 상관 관계를 모델링하는 __회귀분석 기법__ 
-> 단순 선형 회귀 : Y=β0+β1X+ϵ, 다중 선형 회귀 : Y=β0+β1X1+...+βpXp+ϵ
## 선형 회귀 사용법
&nbsp;선형 예측 함수를 사용해 회귀식을 모델링하며, 알려지지 않은 파라미터는 데이터로부터 추정
## 선형 회귀 사용하는 이유
&nbsp;알려지지 않은 파라미터에 대해 선형 관계를 갖는 모델을 세우는 것이, 비선형 관계를 갖는 모델을 세우는 것보다 용이하
# 손실 함수
## 손실 함수 개념
&nbsp;신경망이 학습할 수 있도록 해주는 지표
### 평균 제곱 오차(MSE)
&nbsp;계산이 간편하여 가장 많이 사용되는 손실 함수, 기본적으로 모델의 출력 값과 사용자가 원하는 출력 값 사이의 거리 차이를 오차로 사용하는데 오차를 계산할 때 단순히 거리 차이를 합산하여 평균내게 되면, 거리가 음수로 나왔을 때 합산된 오차가 실제 오차보다 줄어드는 경우가 생기기 때문에 각 거리 차이를 제곱하여 합산한 후에 평균내는 것 -> 
!<img src="https://t1.daumcdn.net/cfile/tistory/999E973A5A9273A405" style="cursor: pointer;max-width:100%;height:auto" width="250" height="83" filename="e 4.1.png" filemime="image/jpeg" original="yes">
### 교차 엔트로피 오차
&nbsp;교차 엔트로피 오차는 기본적으로 분류(Classification) 문제에서 원-핫 인코딩(one-hot encoding)했을 경우에만 사용할 수 있는 오차 계산법이다. 위의 식에서 t값이 원-핫 인코딩된 벡터이고, 거기에다 모델의 출력 값에 자연로그를 취한 것이 곱해지는 형태이다. 결과적으로 교차 엔트로피 오차는 정답일 때의 모델 값에 자연로그를 계산하는 식이 된다. 
!<img src="https://t1.daumcdn.net/cfile/tistory/99C0D73B5A92769625" style="cursor: pointer;max-width:100%;height:auto" width="250" height="78" filename="e 4.2.png" filemime="image/jpeg" original="yes">
## 손실 함수 목적
&nbsp;머신러닝 모델의 최종적인 목적은 높은 정확도를 끌어내는 매개변수(가중치, 편향)를 찾는 것, 신경망 학습에서는 최적의 매개변수를 탐색할 때 손실함수의 값을 가능한 한 작게 하는 매개변수 값을 찾는다. 이 때, 매개변수의 미분(기울기)을 계산하고, 그 미분 값을 토대로 매개변수 값을 갱신하는 과정을 반복
# 경사 하강법
## 경사 하강법 개념
&nbsp;머신러닝 모델은 학습 시에 최적의 매개변수(가중치와 편향)를 찾는데, 최적이란 손실 함수가 최솟값이 될 때의 매개변수 값을 의미. 따라서 __기울기를 이용하여 손실 함수의 최솟값을 찾으려는 것__이 바로 경사법 <br/>

## 경사 하강법 사용처
일반적으로 기계 학습을 최적화하는데 사용되고, 특히나 신경망 학습에 많이 사용
![src](https://kolikim.tistory.com/37?category=733477)
## 데이터 전처리

경사 하강법의 안정적인 적용과 학습의 안정성 및 속도를 높이기 위하여, 학습 전에 데이터를 처리해주는 것이 필요하다. 데이터의 중심이 0이 되게 하거나(zero-centered data), 데이터가 항상 일정한 범위 안에 들어오도록 정규화(normalization)하는 것
이진 분류
------------------------------------------------------
# 퍼셉트론 
## 퍼셉트론 개념
&nbsp;초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘(모든 학습 데이터를 정확히 분류시킬 때까지 학습이 진행되기 때문에 학습 데이터가 선형적으로 분리될 수 있을 때 적합한 알고리즘)
![image](https://image.slidesharecdn.com/lecture29-convolutionalneuralnetworks-visionspring2015-150504114140-conversion-gate02/95/lecture-29-convolutional-neural-networks-computer-vision-spring2015-9-638.jpg?cb=1430740006)
-> 위 이미지에서 가중치라고 부르는 이 weight는 각각의 입력신호에 부여되어 입력신호와의 계산을 하고 신호의 총합이 정해진 임계값(θ; theta,세타)을 넘었을 때 1을 출력한다. (이를 뉴련의 활성화activation 으로도 표현) 넘지 못하면 0 또는 -1을 출력한다.
각 입력신호에는 고유한 weight가 부여되며 weight가 클수록 해당 신호가 중요하다고 볼 수 있음
## 퍼셉트론 한계
&nbsp;직선 하나로 나눈 영역만 표현할 수 있어 XOR과 같은 데이터 형태는 분류가 불가능
![image](<img style="-webkit-user-select: none;margin: auto;" src="http://ecee.colorado.edu/~ecen4831/lectures/xor2.gif">)
# 로지스틱 회귀
## 로지스틱 회귀 개념
&nbsp;독립 변수의 선형 결합을 이용하여 사건의 발생 가능성을 예측하는데 사용되는 통계 기법
시그모이드 함수 -> 실제 많은 자연, 사회현상에서는 특정 변수에 대한 확률값이 선형이 아닌 S-커브 형태를 따르는 경우가 많다. 
이러한 S-커브를 함수로 표현해낸 것이 바로 로지스틱 함수이고, 분야에 따라 시그모이드 함수로도 불림

로지스틱 함수는 x값으로 어떤 값이든 받을 수가 있지만 출력 결과는 항상 0에서 1사이 값이 된다. 즉 확률밀도함수(probability density function) 요건을 충족시키는 함수라는 이야기인데, 그래프 모양 밑 주소 참고
![image](http://i.imgur.com/E0eI8OU.png)
## 승산이란 ?
&nbsp;임의의 사건 A가 발생하지 않을 확률 대비 일어날 확률의 비율을 뜻하는 개념
식으로 쓰자면 == > odds=P(A)/P(Ac)=P(A)/1−P(A)
